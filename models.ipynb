{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb52ba5-286f-4abd-95d3-990aa97a3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.applications.mobilenet_v2  import MobileNetV2\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77af0a21-d4d6-4b28-b3fa-410093690236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to freeze layers of the base model\n",
    "def freeze_layers(base_model):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b973ed65-a0c4-4884-acd7-fcd0dfd99d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to build and compile model\n",
    "def build_model(base_model, input_shape, metrics):\n",
    "    input_layer = keras.Input(shape=input_shape)\n",
    "    \n",
    "    x = base_model(input_layer, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    output_layer = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                  loss=keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ebf639c-42a3-46dd-b174-3bd793483222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to print performance metrics\n",
    "def print_metric(model_name, history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    print(model_name)\n",
    "    print(f\"acc: {acc}\\tval acc: {val_acc}\")\n",
    "    print(f\"loss: {loss}\\tval loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f87a42-74ff-4bab-b16d-c9f90ec1d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [keras.metrics.Accuracy(),keras.metrics.Precision(),keras.metrics.Recall()] # to use on each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "013899a7-705e-4344-9cb7-e78391f9e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape= (224,224,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96970cf-9e62-4ac8-a743-2bea4a525866",
   "metadata": {},
   "source": [
    "VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea37a1f2-8497-463d-a627-1d2944783b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16 base model\n",
    "base_model_vgg16 = VGG16(\n",
    "    input_shape=input_shape,\n",
    "    weights='imagenet',\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0823b044-7508-4ec9-a407-7335f71ee1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making layers not trainable for vgg16's pretrained weights not to change, so we can use pre-trained model\n",
    "freeze_layers(base_model_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22e1e5fb-ff58-450d-ad48-2374b36c5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding layers on top of pre-trained model and creating customized model\n",
    "model_vgg16 = build_model(base_model_vgg16, input_shape, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15509658-0661-4cf1-a30a-0c5ec71398eb",
   "metadata": {},
   "source": [
    "VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99825838-316e-4637-8528-a758b2508849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg19 base model\n",
    "base_model_vgg19 = VGG19(\n",
    "    input_shape=input_shape,\n",
    "    weights='imagenet',\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3c5cd04-dfa4-4f8c-bcaa-6982e67fe250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making layers not trainable for pretrained weights not to change, so we can use pre-trained model\n",
    "freeze_layers(base_model_vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9253d54-b1a2-4b74-a3f6-8cc2a1ded79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding layers on top of pre-trained model and creating customized model\n",
    "model_vgg19 = build_model(base_model_vgg19, input_shape, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2eedcd-1c81-4d92-9434-8e1637bc4cee",
   "metadata": {},
   "source": [
    "RESNET50v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "670f9917-7d57-4bac-ba41-4355f999a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50v2 base model\n",
    "base_model_rn50v2 = ResNet50V2(\n",
    "    input_shape=input_shape,\n",
    "    weights='imagenet',\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "423f5ffa-1d46-49f7-a428-59e42c987b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making layers not trainable for pretrained weights not to change, so we can use pre-trained model\n",
    "freeze_layers(base_model_rn50v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea648a74-d0ad-481f-902c-f6ce278b2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding layers on top of pre-trained model and creating customized model\n",
    "model_rn50v2 = build_model(base_model_rn50v2, input_shape, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf66ee-a3cf-4862-8462-d7022c7f2fce",
   "metadata": {
    "tags": []
   },
   "source": [
    "MOBILENETv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c49423cb-63db-49c6-8c63-b40812775d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenetv2 base model\n",
    "base_model_mbnv2 = MobileNetV2(\n",
    "    input_shape=input_shape,\n",
    "    weights='imagenet',\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99e5d277-7988-4527-a486-d7448867cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making layers not trainable for pretrained weights not to change, so we can use pre-trained model\n",
    "freeze_layers(base_model_mbnv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b82a4685-cc18-48db-9f87-79952b633fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding layers on top of pre-trained model and creating customized model\n",
    "model_mbnv2 = build_model(base_model_mbnv2, input_shape, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fa33a-87e0-4058-aa65-ce58bc72702d",
   "metadata": {},
   "source": [
    "EFFICIENTNETB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3d26c31-ecad-401d-be35-b7f89bbd2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#efficientnetb0 base model\n",
    "base_model_efnb0 = EfficientNetB0(\n",
    "    input_shape=input_shape,\n",
    "    weights='imagenet',\n",
    "    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6da2531-cfee-4c2b-80c0-b358daad8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making layers not trainable for pretrained weights not to change, so we can use pre-trained model\n",
    "freeze_layers(base_model_efnb0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d8827e5-89d8-4cbf-b5d1-864925a5be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding layers on top of pre-trained model and creating customized model\n",
    "model_efnb0 = build_model(base_model_efnb0, input_shape, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e41dc4-ad97-4675-896d-60591ae52a10",
   "metadata": {},
   "source": [
    "MODEL TRAINING FOR 10 EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98cfa6c-93eb-4080-b6bb-19fbda90784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_vgg16 = model_vgg16.fit(train, epochs=10, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e631ba-2bac-4b57-a475-22639047e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_vgg19 = model_vgg16.fit(train, epochs=10, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e589382-4a5b-4f63-afcd-2323c64cbc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_rn50v2 = model_vgg16.fit(train, epochs=10, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe8ae9-015c-47b3-a505-9aabf7648fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mbnv2 = model_vgg16.fit(train, epochs=10, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3befffbc-3e98-4041-9af1-3bc46ca80160",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_efnb0 = model_vgg16.fit(train, epochs=10, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd5fbb-9fad-4088-9b68-a8e17ad4a777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_metric('VGG16',hist_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5653009f-d8d2-402c-be8b-0251538e88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metric('VGG19',hist_vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7ffcd-52c0-4fc4-b5ee-3215e106c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metric('ResNet50v2',hist_rn50v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005cfec4-07f2-416e-b123-e06e45e2860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metric('MobileNetv2',hist_mbnv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daab14a-00a1-4a63-a81c-b7bfa4bd0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metric('EfficientNetB0',hist_efnb0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f2cbc-3a97-460c-b74c-3952b6fa62ae",
   "metadata": {},
   "source": [
    "MODEL TRAINING FOR 100 EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868676ca-32f4-411b-a3ff-8844b432d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_vgg16 = model_vgg16.fit(train, epochs=100, validation_data=val)\n",
    "# model_vgg16.save('vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c04fa8-e64b-4bae-8726-7315a3f3f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_vgg19 = model_vgg19.fit(train, epochs=100, validation_data=val)\n",
    "# model_vgg19.save('vgg19.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439dd873-6695-4698-b052-0d457f4ab00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_rn50v2 = model_rn50v2.fit(train, epochs=100, validation_data=val)\n",
    "# model_rn50v2.save('rn50v2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79ae22-3f2b-4373-bf19-d9524c80b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_mbnv2 = model_mbnv2.fit(train, epochs=100, validation_data=val)\n",
    "# model_mbnv2.save('mbnv2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95babd-5f2e-48ac-89f1-0645504f2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_efnb0 = model_efnb0.fit(train, epochs=100, validation_data=val)\n",
    "# model_efnb0.save('efnb0.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avmproject_env",
   "language": "python",
   "name": "avmproject_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
